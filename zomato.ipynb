{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydWLuio2v7BM"
      },
      "source": [
        "## **1. Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYA-NlNovwIl",
        "outputId": "327bdafa-4c13-4e3a-819a-1bb01d5a3d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.173.89)] [C\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# ─── Install Dependencies ─────────────────────────────────────────────────────\n",
        "!apt-get update -y && apt-get install -y tesseract-ocr\n",
        "!pip install --quiet \\\n",
        "    gradio pytesseract Pillow requests \\\n",
        "    sentence-transformers faiss-cpu transformers \\\n",
        "    torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o49gmhCHxLu-"
      },
      "source": [
        "## **2. Importing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rqGwyvB6vwFG"
      },
      "outputs": [],
      "source": [
        "# Importing regular expressions, HTTP request, and Gradio for the interface\n",
        "import re\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "# To handle image data in memory\n",
        "from io import BytesIO\n",
        "\n",
        "# For image processing\n",
        "from PIL import Image\n",
        "\n",
        "# For Optical Character Recognition (OCR)\n",
        "import pytesseract\n",
        "\n",
        "# Sentence embedding model for semantic search\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# FAISS for efficient vector similarity search\n",
        "import faiss\n",
        "\n",
        "# Transformers for text summarization / generation tasks\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVBycATowuRp"
      },
      "source": [
        "## **3. Menu Image URLs for Each Restaurant**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-VQ4Cm2KvwCy"
      },
      "outputs": [],
      "source": [
        "# ─── Dictionary to Store Static Menu Image URLs ──────────────────────────────\n",
        "# Each restaurant is a key in the dictionary, mapped to a list of image URLs of their menu\n",
        "RESTAURANT_MENUS = {\n",
        "   \"Pukhtaan\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/feb85f6fa20259fe481a7bc440c24476.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/10691ec61acb78405f5961a3d22a42f2.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/460c2011d7dfda6acf1be4dbf8a73da7.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/7e77459a125abd77aed34f7a882ad7e7.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/e08b90bf17c69fbe518c79c11ff6db7f.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/7672cc353331bd91ed471104de6192b5.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/d0f40d75623a98ebc9e8527c2bc0d5e6.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/ead678286bc10afb1f1a6c3bb94ecf10.jpg\",\n",
        "    ],\n",
        "    \"Connaught_Club_House\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/faf36abd62cb22e25492a1e51d36d971.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/6d533623bfb316c927d5087a1be26f1b.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/92fdde9055013c6ab9ba7e9b76c1770d.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/d59c8c08538a220438fab471790d2b3b.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/d5ff7bf34e11499d79ee59b5492e892d.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/5757370e09010293de96576c65c499f3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/e784555ca0fac7f4b2c78ad12d708108.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/cf56b2e45236ab81e3adeebde09937e5.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/b3a95e356d17115f48f31e488fa14510.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/db6351e453b6a553e2a95a029ccd5c93.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/63668b33e2cd94b084aba2400a32302d.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/28c47c6101f4b6525ae0f00054685f7b.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/8580a3bc941162b7ac0fcf6a2b29408f.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/9e199b47a96c620137325a2edaa257ea.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/a48b905eda7e351ec9d16be38263c6ce.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/e1256a12cfc8d2671887daf5849462c3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/407cf6d0c92226a1e8d3c2e306bc7eee.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/a06bc4526e30e16cd66e7fc33680ddd1.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/f43d42f35215a54255c2b3c5e7bc361d.jpg\"\n",
        "    ],\n",
        "    \"Local\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/4a261b83c8d83e45c90ba18738606383.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/e594cde054e3b9cd74bada9713d45647.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/09f07621c6c933873eaa0e3cc2d8cee6.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/9df0e7ea170f93df343a776cbb433b2e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/c7a32dfe8174158daf3395a2d8a3122a.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/6213b5c0e0e6304b496aa40ec29ee7c0.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/62bb0f0ab165aed9aac2f07386be6ce0.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/9bb62a9813fd95783befe1f938dff819.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/39c8d9378a98634edad40bd2e21c8269.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/360/18382360/9059e84501429b654a3b187f8fa05f3b.jpg\"\n",
        "    ],\n",
        "    \"Roofberries\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/2bee857f808bf90d3a339432e3a9a97a.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/177310b350732ea411fce4ee922ce00c.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/c96d1f09849034960eb591d821a9255e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/8eba87e7fc2ba0a32cb8ca73ce72e159.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/331391a9f9e30a09b1fe30a87c89b088.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/4fbe208100d596c5239518143fef18be.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/e232cbceaa3ac5ac4d66f91a18156cb3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/e232cbceaa3ac5ac4d66f91a18156cb3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/9d27ecac94a5815f62fe77fed142996b.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/40787d97f1db990c4199bda163a3f006.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/ce5f056e39226e5d1cc705b197116fc0.jpg\"\n",
        "    ],\n",
        "    \"QEY\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/5fee9979bef7ea53f215f1eff035a98f.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/4ab2a194e0ef6b0976e94d55401aa815.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/cf7fb24e217cf17bf8884e3415bb333c.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/81cdfc3844a6c8adf4df6703f58435cc.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/a1843c6cc22ea5a9a8e00ae79e75fdf2.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8466ea20afd3ba86a4742cd77b438def.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8466ea20afd3ba86a4742cd77b438def.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/400e7dbc0b344795a3e937d0f3b7e07e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/035bdb561621fc8ab19a89561e13f977.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/035bdb561621fc8ab19a89561e13f977.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/6f9151dff3d95c75f045151497b38fe9.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/48ba28da967d96653d8255d4197988c1.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/60b2ac9ef657dde53df1bf3026ab7083.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/73b22be7bae1ac5650e1ee9084a186ac.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/facad6ef851470f4313c134f2e59265e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8afaa475084fc676f842ec067f4888fb.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/fde5ab708e230a214ea2b0defa1f3f1a.jpg\"\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Ip4XIowvDZ"
      },
      "source": [
        "## **4. OCR-Based Menu Digitization & Text Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fyh8YdWVvwAs"
      },
      "outputs": [],
      "source": [
        "# Function: ocr_text(url)\n",
        "# Purpose: Takes an image URL, downloads the image, and extracts text using Tesseract OCR\n",
        "# Parameters:\n",
        "#   url (str): The URL of the image to process\n",
        "# Returns:\n",
        "#   str: Raw extracted text from the image\n",
        "def ocr_text(url):\n",
        "    r = requests.get(url, timeout=15)  # Fetch image with timeout\n",
        "    r.raise_for_status()  # Raise error if request fails\n",
        "    img = Image.open(BytesIO(r.content))  # Load image from byte stream\n",
        "    return pytesseract.image_to_string(img)  # Perform OCR and return text\n",
        "\n",
        "\n",
        "# Function: clean_txt(txt)\n",
        "# Purpose: Cleans and standardizes the raw OCR text for improved processing\n",
        "# Parameters:\n",
        "#   txt (str): The raw text extracted from an image\n",
        "# Returns:\n",
        "#   str: Cleaned and corrected version of the text\n",
        "def clean_txt(txt):\n",
        "    # Remove unwanted special characters (retain prices, symbols, and common punctuations)\n",
        "    txt = re.sub(r'[^A-Za-z0-9\\s\\.,₹$€¥¢&+()/-]', '', txt)\n",
        "\n",
        "    # Dictionary of common OCR misreads and domain-specific corrections\n",
        "    fixes = {\n",
        "        r'\\b(O|0)e\\b':         'Of',                      # Correct misread 'Of'\n",
        "        r'\\bPaneera?\\b':       'Paneer',                  # Correct OCR spelling of Paneer\n",
        "        r'\\bMurgh\\b':          'Chicken',                 # Standardize 'Murgh' to 'Chicken'\n",
        "        r'\\bCCH\\b':            'Connaught_Club_House',    # Expand restaurant abbreviation\n",
        "        r'\\bR\\s*(\\d+)':        r'₹\\1',                    # Normalize currency notation\n",
        "        r'\\b(\\d{1,3})\\s*-\\s*(\\d{1,3})\\b': r'₹\\1-₹\\2',      # Normalize price ranges\n",
        "        r'\\b[Tt]andoori\\s+Alo\\b':'Tandoori Aloo'          # Correct common dish OCR error\n",
        "    }\n",
        "\n",
        "    # Apply all replacements using regex\n",
        "    for pat, rep in fixes.items():\n",
        "        txt = re.sub(pat, rep, txt, flags=re.IGNORECASE)\n",
        "\n",
        "    return txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsIBxs2DwvjK"
      },
      "source": [
        "## **5. Parsing Menu Text and Tagging Items**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xLBZmGeBvv-g"
      },
      "outputs": [],
      "source": [
        "# ─── Step 5.1: Parse Cleaned Menu Text into Structured Items ─────────────────────\n",
        "def parse_menu(raw):\n",
        "    # Clean and split input into non-empty lines\n",
        "    lines = [l.strip() for l in clean_txt(raw).splitlines() if l.strip()]\n",
        "\n",
        "    # Regular expression to capture price patterns like ₹120, Rs. 250, etc.\n",
        "    price_re = re.compile(r'(₹|Rs\\.?|INR)\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', re.I)\n",
        "\n",
        "    items, cur = [], None  # List to store parsed items, and a placeholder for current item\n",
        "\n",
        "    for ln in lines:\n",
        "        m = price_re.search(ln)\n",
        "\n",
        "        # If line contains a price and we have a current item, assign the price and store the item\n",
        "        if m and cur:\n",
        "            cur['price'] = m.group().strip()\n",
        "            items.append(cur)\n",
        "            cur = None\n",
        "\n",
        "        # If line looks like a new item name (starts with uppercase and is sufficiently long)\n",
        "        elif ln[0].isupper() and len(ln) > 3:\n",
        "            if cur: items.append(cur)  # Save previous item if still pending\n",
        "            cur = {'name': ln, 'price': '', 'description': ''}  # Start new item\n",
        "\n",
        "        # Otherwise, treat the line as a description for the current item\n",
        "        elif cur:\n",
        "            cur['description'] += ' ' + ln\n",
        "\n",
        "    if cur: items.append(cur)  # Add the last item if not already added\n",
        "    return items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HCMmgScRzZu9"
      },
      "outputs": [],
      "source": [
        "# ─── Step 5.2: Tag Items with Dietary and Spice Information ──────────────────────\n",
        "def tag_items(items):\n",
        "    # Non-vegetarian keywords to flag non-veg dishes\n",
        "    diet_non = {'chicken','mutton','fish','prawn','meat','lamb','beef','egg','shrimp','crab'}\n",
        "\n",
        "    # Grouped keywords to identify spice levels\n",
        "    spice_3  = {'extra spicy','fiery','blazing','scorching','ghost pepper'}\n",
        "    spice_2  = {'spicy','chilli','hot','pepper','masala','jalapeno','szechuan','cayenne'}\n",
        "    spice_1  = {'mild','paprika','tandoor','tikka','curry'}\n",
        "\n",
        "    for it in items:\n",
        "        text = (it['name'] + ' ' + it['description']).lower()\n",
        "\n",
        "        # Determine if item is vegetarian by checking absence of non-veg keywords\n",
        "        it['is_veg'] = not any(w in text for w in diet_non)\n",
        "\n",
        "        # Determine spice level based on keyword matches\n",
        "        lvl = 0\n",
        "        if any(w in text for w in spice_1): lvl = 1\n",
        "        if any(w in text for w in spice_2): lvl = 2\n",
        "        if any(w in text for w in spice_3): lvl = 3\n",
        "        it['spice_level'] = lvl\n",
        "\n",
        "    return items\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvHpL8rHwwFi"
      },
      "source": [
        "## **6. Build Restaurant Menu Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N4r_VpySvv7_"
      },
      "outputs": [],
      "source": [
        "restaurant_data = {}  # Dictionary to store structured data for each restaurant\n",
        "\n",
        "# Loop through each restaurant and its corresponding list of menu image URLs\n",
        "for r, urls in RESTAURANT_MENUS.items():\n",
        "    # Apply OCR to all menu images and join the text outputs\n",
        "    pages = [ocr_text(u) for u in urls]\n",
        "\n",
        "    # Parse the joined text into structured items (name, description, price)\n",
        "    items = parse_menu(\"\\n\\n\".join(pages))\n",
        "\n",
        "    # Tag items with dietary info (veg/non-veg) and spice levels\n",
        "    tagged_items = tag_items(items)\n",
        "\n",
        "    # Store the tagged menu items in the dictionary under the restaurant name\n",
        "    restaurant_data[r] = {'items': tagged_items}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtbnJkv7wwej"
      },
      "source": [
        "## **7. Generate Embeddings & Build FAISS Index**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2c1907b505d64cb098e91830a05084dc",
            "a80966e90dd449a3ac101a0cbe241295",
            "99cab769226443b0830e05627c43bd48",
            "d760896978da4e2ebccdff0564496fb3",
            "364ba0fb5db344b881fb470d73ba99ad",
            "56eabe5ec54e4b5eb3919541908956f1",
            "0877f4a27ee74632b109c19ca80273af",
            "7631329eb65343c181c17fa5e13d2eee",
            "5434122651f54532a76b225976274c3a",
            "8296008867c9457c84fb5b3f09cef2f8",
            "cc2f49fc8029485ca9e3db48b9b3b045"
          ]
        },
        "id": "npf2Mt3_vv5q",
        "outputId": "2aab926a-d3b3-479c-fc74-87e92d63091e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c1907b505d64cb098e91830a05084dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/42 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "docs, meta = [], []  # `docs` holds text for embedding, `meta` stores related info\n",
        "\n",
        "# Prepare document strings and metadata for each menu item across restaurants\n",
        "for r, info in restaurant_data.items():\n",
        "    for it in info['items']:\n",
        "        # Create searchable string combining name, description, and restaurant name\n",
        "        docs.append(f\"{it['name']} — {it['description']} [{r}]\")\n",
        "\n",
        "        # Store metadata: restaurant name + item details (price, tags, etc.)\n",
        "        meta.append({'restaurant': r, **it})\n",
        "\n",
        "# Load a lightweight semantic embedder model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Convert text documents into vector embeddings\n",
        "embs = embedder.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# Initialize a FAISS index and add all embeddings for fast similarity search\n",
        "index = faiss.IndexFlatL2(embs.shape[1])\n",
        "index.add(embs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlrQSd4_ww4l"
      },
      "source": [
        "## **8. Setup RAG (Retrieval-Augmented Generation) with FLAN-T5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2d3NstOvv3M",
        "outputId": "3eff058e-3926-4a75-9ec6-79fd42b7911e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained FLAN-T5 model and tokenizer for generating text-based answers\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model     = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "# Create a text2text generation pipeline using the model\n",
        "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "\n",
        "# Define RAG-style question-answering function\n",
        "def rag_answer(q, k=5):\n",
        "    # Convert the question to an embedding vector\n",
        "    qe = embedder.encode([q], convert_to_numpy=True)\n",
        "\n",
        "    # Search for top-k most relevant menu items using FAISS\n",
        "    _, I = index.search(qe, k)\n",
        "\n",
        "    # Construct a context string from the retrieved menu items\n",
        "    ctx = \"\\n\".join(f\"- {docs[i]}\" for i in I[0])\n",
        "\n",
        "    # Build a prompt combining context and the question\n",
        "    prompt = f\"You are a restaurant menu expert.\\nContext:\\n{ctx}\\n\\nQuestion: {q}\\nAnswer:\"\n",
        "\n",
        "    # Generate the answer using the FLAN-T5 pipeline\n",
        "    return pipe(prompt, do_sample=False)[0]['generated_text'].strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-ThQH8AwxUu"
      },
      "source": [
        "## **9. Format Menu Output for Display**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "t4pOm9wUvv0i"
      },
      "outputs": [],
      "source": [
        "def format_menu_output(filtered):\n",
        "    \"\"\"\n",
        "    Nicely formats filtered menu items for clean and readable display.\n",
        "\n",
        "    Parameters:\n",
        "        filtered (list): A list of menu items, each tagged with metadata like\n",
        "                         restaurant name, veg/non-veg, spice level, and price.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted string with icons and groupings by restaurant.\n",
        "    \"\"\"\n",
        "    output = \"\"\n",
        "    current_restaurant = None\n",
        "\n",
        "    # Iterate through the list of filtered menu items\n",
        "    for item in filtered:\n",
        "        # Add a new restaurant section header if restaurant changes\n",
        "        if item['restaurant'] != current_restaurant:\n",
        "            current_restaurant = item['restaurant']\n",
        "            output += f\"\\n---\\n### 🍽 {current_restaurant.replace('_',' ')}\\n\"\n",
        "\n",
        "        # Add veg/non-veg icon\n",
        "        veg_icon = \"🌱 Veg\" if item['is_veg'] else \"🍖 Non-Veg\"\n",
        "\n",
        "        # Show spice level with 🔥 icons or 🌿 for mild\n",
        "        spice_icon = \"🔥\" * item['spice_level'] or \"🌿 Mild\"\n",
        "\n",
        "        # Fallback if price is not available\n",
        "        price = item['price'] or \"Price N/A\"\n",
        "\n",
        "        # Append item info to the output string\n",
        "        output += (\n",
        "            f\"\\n*{item['name']}*  \\n\"\n",
        "            f\"{veg_icon} | {spice_icon}  \\n\"\n",
        "            f\"💰 {price}  \\n\"\n",
        "            f\"{item['description'].strip()}\\n\"\n",
        "        )\n",
        "\n",
        "    return output.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuyzPLNvwx2C"
      },
      "source": [
        "## **10. Build the Chat Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KOezeVy5vvvH"
      },
      "outputs": [],
      "source": [
        "# ─── Step 8: Chat Function ─────────────────────────────────────────────────────\n",
        "\n",
        "def chat_fn(query):\n",
        "    \"\"\"\n",
        "    Main query interface for users to interact with the restaurant menu chatbot.\n",
        "    It performs semantic search, applies keyword filtering, and optionally\n",
        "    uses RAG (Retrieval-Augmented Generation) to respond.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The user's natural language query.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted response either from matched menu items or generated text.\n",
        "    \"\"\"\n",
        "    ql = query.strip().lower()\n",
        "\n",
        "    # 8.1 Semantic retrieval using sentence embeddings\n",
        "    qe = embedder.encode([query], convert_to_numpy=True)\n",
        "    _, I = index.search(qe, 5)\n",
        "    hits = [meta[i] for i in I[0]]\n",
        "\n",
        "    # 8.2 Keyword filtering for more direct, accurate matches\n",
        "    terms = set(ql.split())\n",
        "    filtered = [h for h in hits if terms & set((h['name'] + ' ' + h['description']).lower().split())]\n",
        "\n",
        "    # Return formatted menu if there are direct matches\n",
        "    if filtered:\n",
        "        return format_menu_output(filtered)\n",
        "\n",
        "    # 8.3 Fallback: Use RAG pipeline for broader questions (e.g., comparisons, recommendations)\n",
        "    return rag_answer(query)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLanl7ElwySs"
      },
      "source": [
        "Launch Gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "0UUH2x82vvUC",
        "outputId": "a8ef1a2d-986c-4189-b66c-b16df6c60b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cbb5eaa9649cf61a40.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://cbb5eaa9649cf61a40.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Creating the Gradio interface for the restaurant menu chatbot.\n",
        "gr.Interface(\n",
        "    fn=chat_fn,  # The function to be invoked on user input (chat_fn from previous steps)\n",
        "    inputs=gr.Textbox(  # Input field where users can type queries\n",
        "        lines=2,  # Number of lines for the input box\n",
        "        placeholder=\"e.g. show me chicken dishes\"  # Placeholder text for guidance\n",
        "    ),\n",
        "    outputs=\"markdown\",  # Output format for displaying the results\n",
        "    title=\"🍴 Restaurant Menu Explorer\",  # Title of the interface\n",
        "    description=\"Ask about dishes, dietary filters, spice, prices, comparisons, or any free‐text query.\"  # Interface description\n",
        ").launch(share=True)  # Launches the interface and shares a public link for access\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9aFqWQkqnk7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
